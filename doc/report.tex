\documentclass[12pt,a4paper,oneside,article]{article}

\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{pgf-umlcd} % add "simplified" to hide empty parts in UML
\usepackage{pgf-umlsd}
\usepackage{csquotes}

\usepackage[
backend=biber,
sorting=ynt
]{biblatex}

\addbibresource{report.bib}

\title{Decentralized Distributed Machine Learning}
\author{\href{mailto:filippo.barbari@studio.unibo.it}{Filippo Barbari}}
\date{\today}

\begin{document}
	\maketitle
	
	\begin{abstract}
		Nowadays the amount of data produced by decentralized devices is exponentially increasing and with them the need for well-established data analysis and inference systems. 
		Although data privacy has started to be a central theme in public debate, many commercial (e.g. profiling users) and research (e.g. collector of medical data) systems donâ€™t take it into account. Therefore the aim of this project is to develop a library for tackling the resolution of simple inference tasks using machine learning models trained in a decentralized manner. The goal is pursued by developing a network-based system in which each node sees only its data (i.e. it complies with privacy constraints) and thus owns a partial version of the model. The final optimized version is obtained using a message-passing approach in which nodes exchange gradient partitions each other. Furthermore, this approach could be used to tackle the problem of managing huge datasets (i.e. scenarios in which memory is limited) by giving each node only a circumscribed subset.
	\end{abstract}
	\clearpage
	
	\tableofcontents
	\clearpage
	
	\section{Goal/Requirements}
		Detailed description of the project goals, requirements, and expected outcomes.
		
		Use case Diagrams, examples, or Q/A simulations are welcome.
		
		\subsection{Scenarios}
			Informal description of the ways users are expected to interact with your project. It should describe how and why a user should use / interact with the system.
			
		\subsection{Self-assessment policy}
			How should the quality of the produced software be assessed?
			
			How should the effectiveness of the project outcomes be assessed?
	
	\section{Requirement Analysis}
		Is there any implicit requirement hidden within this project's requirements?
		
		Is there any implicit hypothesis hidden within this project's requirements?
		
		Are there any non-functional requirements implied by this project's requirements?
		
		What model/paradigm/techonology is the best suited to face this project's requirements?
		
		What's the abstraction gap among the available models/paradigms/techonologies and the problem to be solved?
		
		The following requirements are considered \textbf{mandatory} in order to successfully deliver the project. Technologies that will be used are listed as well.
		
		\begin{enumerate}
			\item The algorithm used to implement the training process is described in \cite{watcharapichat2016ako}. Briefly it is divided into gradients calculus, accumulation and exchange between worker
			\item The node that starts the computation, thus becoming the \emph{principal} one, can choose different training settings, such as the task and related model, workers among those available in the network and a stopping criterion (e.g. target epoch reached)
			\item Provide support for most commonly used Scikit-learn models such as Logistic Regression
			\item Peers will be able to join the network at any time. They will not be able to join a training process, once it has started, while being able to disconnect from both at any time
			\item Monitoring real-time metrics (e.g. accuracy) in order to assess correct convergence
			\item As soon as the training process finishes, the resulting model will be sent back to the \emph{principal} node, that will optionally be able to download it in ONNX format
			\item Implement a significant case study, e.g. classification using a Logistic Regression model
			\item Test the aforementioned case study emulating different scenarios, e.g. high number of peers or high network latency
			\item The project will be delivered in the form of a Docker container image on Docker Hub at this \href{https://hub.docker.com/repository/docker/filippobarbari/ddml-peer}{link}
		\end{enumerate}
	
	\section{Design}
		This is where the logical/abstract contribution of the project is presented.
		
		Notice that, when describing a software project, three dimensions need to be taken into account: structure, behaviour, and interaction.
		
		Always remember to report why a particular design has been chosen. Reporting wrong design choices which has been evaluated during the design phase is welcome too.
		
		\subsection{Structure}
			Which entities need to be modelled to solve the problem?
			
			\texttt{Worker}, \texttt{Peer} and \texttt{InteractivePeer} follow the same API of the class \texttt{Thread} found in the \texttt{threading} module of Python's standard library.
			
			\begin{tikzpicture}
				\begin{class}[text width=3cm]{Thread}{0,0}
					\attribute{name : String}
					\operation{start()}
					\operation{run()}
					\operation{join()}
					\operation{is\_alive() : bool}
				\end{class}
			
				\begin{class}[text width=3cm]{Worker}{0,-4}
					\inherit{Thread}
					\operation{die()}
					\operation{is\_shutdown() : bool}
				\end{class}
			
				\begin{class}[text width=3cm]{Peer}{0,-7}
					\inherit{Worker}
					\attribute{knownPeers : List[Peer]}
					\attribute{trainingPeers : List[Peer]}
					\operation{???}
				\end{class}
			
				\begin{class}[text width=3cm]{InteractivePeer}{0,-11}
					\inherit{Peer}
					\attribute{???}
					\operation{is\_training() : bool}
					\operation{start\_train()}
				\end{class}
			\end{tikzpicture}
			
			How should entities be modularised?
			
			(UML Component/Package/Deployment Diagrams)
		
		\subsection{Behaviour}
			How should each entity behave?
			
			\begin{tikzpicture}[stateNode/.style={rectangle split, rectangle split parts=2, draw, rounded corners, fill=yellow!10}]
				\node[stateNode]{
					\tikz\node[draw=red, rectangle, rounded corners]{title};
					\nodepart{two}
					\begin{tabular}{c}
						content \\ more content
					\end{tabular}
				};
			\end{tikzpicture}
			
		\subsection{Interaction}
			How should entities interact with each other?
			
			\begin{sequencediagram}
				\newthread[blue]{s1}{:Server1}
				\newinst{db}{:Database}
				\newthread[red]{s2}{:Server2}
				\begin{call}{s1}{reading}{db}{data}
					\postlevel
				\end{call}
				\prelevel\prelevel
				\setthreadbias{east}
				\begin{call}{s2}{reading}{db}{data}
					\postlevel
				\end{call}
			\end{sequencediagram}
			
	\section{Implementation Details}
		Just report interesting / non-trivial / non-obvious implementation details.
		
		This section is expected to be short in case some documentation (e.g. Javadoc or Swagger Spec) has been produced for the software artifacts. This this case, the produced documentation should be referenced here.
		
	\section{Self-assessment}
		Choose a criterion for the evaluation of the produced software and \textbf{its compliance to the requirements above}.
		
		Pseudo-formal or formal criteria are preferred.
		
		In case of a test-driven development, describe tests here and possibly report the amount of passing tests, the total amount of tests and, possibly, the test coverage.
		
	\section{Deployment Instructions}
		Explain here how to install and launch the produced software artifacts. Assume the softaware must be installed on a totally virgin environment. So, report any conviguration step.
		
		Gradle and Docker may be useful here to ensure the deployment and launch processes to be easy.
		
	\section{Usage Examples}
		Show how to use the produced software artifacts.
		
		Ideally, there should be at least one example for each scenario proposed above.
		
	\section{Conclusion}
		Reacp what you did.
		
		\subsection{Future works}
			Recap what you didn't do.
		
		\subsection{What we learned}
			Recap what you learned.
			
	\printbibliography
\end{document}